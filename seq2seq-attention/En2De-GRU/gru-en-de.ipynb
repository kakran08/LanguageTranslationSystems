{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f0e983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import zipfile\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import tokenizers\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "592e2aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0+cu129\n",
      "CUDA available: True\n",
      "CUDA version (torch): 12.9\n",
      "CUDA runtime version (driver): 12.9\n",
      "Device name: NVIDIA GeForce RTX 2050\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version (torch): {torch.version.cuda}\")\n",
    "print(f\"CUDA runtime version (driver): {torch.version.cuda}\")\n",
    "print(f\"Device name: {torch.cuda.get_device_name(0)}\" if torch.cuda.is_available() else \"No CUDA device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "608a47cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs: 320340\n"
     ]
    }
   ],
   "source": [
    "def normalize(line):\n",
    "    line = unicodedata.normalize(\"NFKC\", line)\n",
    "    parts = line.split('\\t')\n",
    "    en, de = parts[0], parts[1]\n",
    "    return  en.lower().strip(), de.lower().strip()\n",
    "\n",
    "text_pairs = []\n",
    "with open(\"de.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        en , de = normalize(line)\n",
    "        text_pairs.append((en,de))\n",
    "\n",
    "print(f\"Pairs: {len(text_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb428ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"en_tokenizer.json\") and os.path.exists(\"de_tokenizer.json\"):\n",
    "    en_tokenizer = tokenizers.Tokenizer.from_file(\"en_tokenizer.json\")\n",
    "    de_tokenizer = tokenizers.Tokenizer.from_file(\"de_tokenizer.json\")\n",
    "else:\n",
    "    en_tokenizer = tokenizers.Tokenizer(tokenizers.models.BPE())\n",
    "    de_tokenizer = tokenizers.Tokenizer(tokenizers.models.BPE())\n",
    "\n",
    "    # Configure pre-tokenizer to split on whitespace and punctuation, add space at beginning of the sentence\n",
    "    en_tokenizer.pre_tokenizer = tokenizers.pre_tokenizers.ByteLevel(add_prefix_space=True)\n",
    "    de_tokenizer.pre_tokenizer = tokenizers.pre_tokenizers.ByteLevel(add_prefix_space=True)\n",
    "\n",
    "    # Configure decoder: So that word boundary symbol \"Ġ\" will be removed\n",
    "    en_tokenizer.decoder = tokenizers.decoders.ByteLevel()\n",
    "    de_tokenizer.decoder = tokenizers.decoders.ByteLevel()\n",
    "\n",
    "    # Train BPE for English and French using the same trainer\n",
    "    VOCAB_SIZE = 20000\n",
    "    trainer = tokenizers.trainers.BpeTrainer(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        special_tokens=[\"[start]\", \"[end]\", \"[pad]\"],\n",
    "        show_progress=True\n",
    "    )\n",
    "    en_tokenizer.train_from_iterator([x[0] for x in text_pairs], trainer=trainer)\n",
    "    de_tokenizer.train_from_iterator([x[1] for x in text_pairs], trainer=trainer)\n",
    "\n",
    "    en_tokenizer.enable_padding(pad_id=en_tokenizer.token_to_id(\"[pad]\"), pad_token=\"[pad]\")\n",
    "    de_tokenizer.enable_padding(pad_id=de_tokenizer.token_to_id(\"[pad]\"), pad_token=\"[pad]\")\n",
    "\n",
    "    # Save the trained tokenizers\n",
    "    en_tokenizer.save(\"en_tokenizer.json\", pretty=True)\n",
    "    de_tokenizer.save(\"de_tokenizer.json\", pretty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20da4d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tokenization:\n",
      "Original: tom plays the flute.\n",
      "Tokens: ['Ġtom', 'Ġplays', 'Ġthe', 'Ġflute', '.']\n",
      "IDs: [101, 2292, 100, 5291, 13]\n",
      "Decoded:  tom plays the flute.\n",
      "\n",
      "Original: tom spielt flöte.\n",
      "Tokens: ['[start]', 'Ġtom', 'Ġspielt', 'ĠflÃ¶te', '.', 'Ġ', '[end]']\n",
      "IDs: [0, 118, 1467, 7982, 13, 76, 1]\n",
      "Decoded:  tom spielt flöte. \n",
      "\n",
      "Vocab Size:\n",
      "English: 20000\n",
      "Deutsch: 20000\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample tokenization:\")\n",
    "en_sample, de_sample = random.choice(text_pairs)\n",
    "encoded = en_tokenizer.encode(en_sample)\n",
    "print(f\"Original: {en_sample}\")\n",
    "print(f\"Tokens: {encoded.tokens}\")\n",
    "print(f\"IDs: {encoded.ids}\")\n",
    "print(f\"Decoded: {en_tokenizer.decode(encoded.ids)}\")\n",
    "print()\n",
    "\n",
    "encoded = de_tokenizer.encode(\"[start] \" + de_sample + \" [end]\")\n",
    "print(f\"Original: {de_sample}\")\n",
    "print(f\"Tokens: {encoded.tokens}\")\n",
    "print(f\"IDs: {encoded.ids}\")\n",
    "print(f\"Decoded: {de_tokenizer.decode(encoded.ids)}\")\n",
    "print()\n",
    "\n",
    "print(\"Vocab Size:\")\n",
    "print(f\"English: {len(en_tokenizer.get_vocab())}\")\n",
    "print(f\"Deutsch: {len(de_tokenizer.get_vocab())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0b2808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create PyTorch dataset for the BPE-encoded translation pairs\n",
    "#\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, text_pairs):\n",
    "        self.text_pairs = text_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        en, de = self.text_pairs[idx]\n",
    "        return en, \"[start] \" + de + \" [end]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c7592bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    en, de = zip(*batch)\n",
    "    en_enc = en_tokenizer.encode_batch(en, add_special_tokens=True)\n",
    "    de_enc = en_tokenizer.encode_batch(de, add_special_tokens=True)\n",
    "\n",
    "    en_ids = [enc.ids for enc in en_enc]\n",
    "    de_ids = [enc.ids for enc in de_enc]\n",
    "\n",
    "    return torch.tensor(en_ids), torch.tensor(de_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aded91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "dataset = Dataset(text_pairs)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5993c420",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    \"\"\"A RNN encoder with an embedding layer\"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, dropout=0.1, num_layers=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            vocab_size: The size of the input vocabulary\n",
    "            embedding_dim: The dimension of the embedding vector\n",
    "            hidden_dim: The dimension of the hidden state\n",
    "            dropout: The dropout rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim, batch_first=True, num_layers=num_layers)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        # input seq = [batch_size, seq_len] -> embedded = [batch_size, seq_len, embedding_dim]\n",
    "        embedded = self.dropout(self.embedding(input_seq))\n",
    "        # outputs = [batch_size, seq_len, hidden_dim]\n",
    "        # hidden = [num_layers, batch_size, hidden_dim]\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3f8790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "     The forward function takes query and keys only, and they should be the same shape (B,S,H)\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        \"\"\"Bahdanau Attention\n",
    "\n",
    "        Args:\n",
    "            query: [B, 1, H]\n",
    "            keys: [B, S, H]\n",
    "\n",
    "        Returns:\n",
    "            context: [B, 1, H]\n",
    "            weights: [B, 1, S]\n",
    "        \"\"\"\n",
    "        B, S, H = keys.shape\n",
    "        assert query.shape == (B, 1, H)\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.transpose(1,2)  # scores = [B, 1, S]\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "        return context, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f16da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.attention = Attention(hidden_dim)\n",
    "        self.gru = nn.GRU(embedding_dim + hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.out_proj = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, input_seq, hidden, enc_out):\n",
    "        \"\"\"Single token input, single token output\n",
    "            \n",
    "        Args:\n",
    "            input_seq: [B, 1] — input token for this timestep\n",
    "            hidden: [num_layers, B, H] — decoder hidden state\n",
    "            enc_out: [B, S, H] — encoder outputs (for attention)\n",
    "\n",
    "        Returns:\n",
    "            output: [B, 1, vocab_size] — logits over vocab\n",
    "            hidden: [num_layers, B, H] — updated hidden state\n",
    "        \"\"\"\n",
    "        # input seq = [batch_size, 1] -> embedded = [batch_size, 1, embedding_dim]\n",
    "        embedded = self.dropout(self.embedding(input_seq))\n",
    "        # hidden = [num_layers, batch_size, hidden_dim]\n",
    "        # query = [batch_size, 1, hidden_dim]\n",
    "        # context = [batch_size, 1, hidden_dim]\n",
    "        query = hidden[-1].unsqueeze(1)  # [B, 1, H]\n",
    "        context, attn_weights = self.attention(query, enc_out)\n",
    "        # rnn_input = [batch_size, 1, embedding_dim + hidden_dim]\n",
    "        rnn_input = torch.cat([embedded, context], dim=-1)\n",
    "        # rnn_output = [batch_size, 1, hidden_dim]\n",
    "        rnn_output, hidden = self.gru(rnn_input, hidden)\n",
    "        output = self.out_proj(rnn_output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b562479",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRNN(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_seq, target_seq):\n",
    "        \"\"\"Given the partial target sequence, predict the next token\"\"\"\n",
    "        # input seq = [batch_size, seq_len]\n",
    "        # target seq = [batch_size, seq_len]\n",
    "        batch_size, target_len = target_seq.shape\n",
    "        device = target_seq.device\n",
    "        # list for storing the output logits\n",
    "        outputs = []\n",
    "        # encoder forward pass\n",
    "        enc_out, hidden = self.encoder(input_seq)\n",
    "        dec_hidden = hidden\n",
    "        # decoder forward pass\n",
    "        for t in range(target_len-1):\n",
    "            # during training, use the ground truth token as the input (teacher forcing)\n",
    "            dec_in = target_seq[:, t].unsqueeze(1)\n",
    "            # last target token and hidden states -> next token\n",
    "            dec_out, dec_hidden = self.decoder(dec_in, dec_hidden, enc_out)\n",
    "            # store the prediction\n",
    "            outputs.append(dec_out)\n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "248de5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Model parameters\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "enc_vocab = len(en_tokenizer.get_vocab())\n",
    "dec_vocab = len(de_tokenizer.get_vocab())\n",
    "emb_dim = 512\n",
    "hidden_dim = 512\n",
    "dropout = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a5e8a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2SeqRNN(\n",
      "  (encoder): EncoderRNN(\n",
      "    (embedding): Embedding(20000, 512)\n",
      "    (rnn): GRU(512, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): DecoderRNN(\n",
      "    (embedding): Embedding(20000, 512)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (attention): Attention(\n",
      "      (Wa): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Ua): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Va): Linear(in_features=512, out_features=1, bias=True)\n",
      "    )\n",
      "    (gru): GRU(1024, 512, batch_first=True)\n",
      "    (out_proj): Linear(in_features=512, out_features=20000, bias=True)\n",
      "  )\n",
      ")\n",
      "Model created with:\n",
      "  Input vocabulary size: 20000\n",
      "  Output vocabulary size: 20000\n",
      "  Embedding dimension: 512\n",
      "  Hidden dimension: 512\n",
      "  Dropout: 0.1\n",
      "  Total parameters: 35204129\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "encoder = EncoderRNN(enc_vocab, emb_dim, hidden_dim, dropout).to(device)\n",
    "decoder = DecoderRNN(dec_vocab, emb_dim, hidden_dim, dropout).to(device)\n",
    "model = Seq2SeqRNN(encoder, decoder).to(device)\n",
    "print(model)\n",
    "\n",
    "print(\"Model created with:\")\n",
    "print(f\"  Input vocabulary size: {enc_vocab}\")\n",
    "print(f\"  Output vocabulary size: {dec_vocab}\")\n",
    "print(f\"  Embedding dimension: {emb_dim}\")\n",
    "print(f\"  Hidden dimension: {hidden_dim}\")\n",
    "print(f\"  Dropout: {dropout}\")\n",
    "print(f\"  Total parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "314d741b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10011/10011 [53:14<00:00,  3.13it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5; Avg loss 0.7702970968600503; Latest loss 0.8347820043563843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10011/10011 [59:37<00:00,  2.80it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5; Avg loss 0.4771934005183162; Latest loss 0.5925331115722656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 10011/10011 [11:44<00:00, 14.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.38059103819513257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10011/10011 [59:42<00:00,  2.79it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5; Avg loss 0.4155243230981196; Latest loss 0.4284461736679077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10011/10011 [1:00:13<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5; Avg loss 0.38332118771969526; Latest loss 0.33460500836372375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 10011/10011 [11:33<00:00, 14.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.31368289969027213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10011/10011 [1:00:15<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5; Avg loss 0.3635944887785844; Latest loss 0.4502602219581604\n"
     ]
    }
   ],
   "source": [
    "# Train unless model.pth exists\n",
    "if os.path.exists(\"en2de_tlate_attn.pth\"):\n",
    "    model.load_state_dict(torch.load(\"seq2seq_attn.pth\"))\n",
    "else:\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "    loss_fn = nn.CrossEntropyLoss() #ignore_index=de_tokenizer.token_to_id(\"[pad]\"))\n",
    "    N_EPOCHS = 5\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for en_ids, de_ids in tqdm.tqdm(dataloader, desc=\"Training\"):\n",
    "            # Move the \"sentences\" to device\n",
    "            en_ids = en_ids.to(device)\n",
    "            de_ids = de_ids.to(device)\n",
    "            # zero the grad, then forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(en_ids, de_ids)\n",
    "            # compute the loss: compare 3D logits to 2D targets\n",
    "            loss = loss_fn(outputs.reshape(-1, dec_vocab), de_ids[:, 1:].reshape(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{N_EPOCHS}; Avg loss {epoch_loss/len(dataloader)}; Latest loss {loss.item()}\")\n",
    "        torch.save(model.state_dict(), f\"en2de_tlate_attn-{epoch+1}.pth\")\n",
    "        # Test\n",
    "        if (epoch+1) % 2 != 0:\n",
    "            continue\n",
    "        model.eval()\n",
    "        epoch_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for en_ids, de_ids in tqdm.tqdm(dataloader, desc=\"Evaluating\"):\n",
    "                en_ids = en_ids.to(device)\n",
    "                de_ids = de_ids.to(device)\n",
    "                outputs = model(en_ids, de_ids)\n",
    "                loss = loss_fn(outputs.reshape(-1, dec_vocab), de_ids[:, 1:].reshape(-1))\n",
    "                epoch_loss += loss.item()\n",
    "        print(f\"Eval loss: {epoch_loss/len(dataloader)}\")\n",
    "    torch.save(model.state_dict(), \"en2de_tlate_attn.pth\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "835cb430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: he can only criticize people behind their backs.\n",
      "Deutsch: er kann leute nur hinter deren rücken kritisieren.\n",
      "Predicted: watte es mngeschlagenonn hinein�� unsymp�h� äraunre� gro hört�hlein.�\n",
      "\n",
      "English: i remember when i was your age.\n",
      "Deutsch: ich weiß noch, als ich so alt war wie du.\n",
      "Predicted: �auwatteenn kann mittlerweileau,urs�au lieen lustige weißt.�\n",
      "\n",
      "English: i've invited my friends.\n",
      "Deutsch: ich habe meine freunde eingeladen.\n",
      "Predicted: �auirriöige trägt sate ist i dein wieein.�\n",
      "\n",
      "English: tom is distracted.\n",
      "Deutsch: tom ist abgelenkt.\n",
      "Predicted:  santomm könleinkt.�\n",
      "\n",
      "English: i like dark chocolate.\n",
      "Deutsch: ich mag dunkle schokolade.\n",
      "Predicted: �auvers herausbekommt sie wel wünschte dar oder.�\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test for a few samples\n",
    "model.eval()\n",
    "N_SAMPLES = 5\n",
    "MAX_LEN = 60\n",
    "with torch.no_grad():\n",
    "    start_token = torch.tensor([de_tokenizer.token_to_id(\"[start]\")]).to(device)\n",
    "    for en, true_fr in random.sample(text_pairs, N_SAMPLES):\n",
    "        en_ids = torch.tensor(en_tokenizer.encode(en).ids).unsqueeze(0).to(device)\n",
    "        enc_out, hidden = model.encoder(en_ids)\n",
    "        pred_ids = []\n",
    "        prev_token = start_token.unsqueeze(0)\n",
    "        for _ in range(MAX_LEN):\n",
    "            output, hidden = model.decoder(prev_token, hidden, enc_out)\n",
    "            output = output.argmax(dim=2)\n",
    "            pred_ids.append(output.item())\n",
    "            prev_token = output\n",
    "            # early stop if the predicted token is the end token\n",
    "            if pred_ids[-1] == de_tokenizer.token_to_id(\"[end]\"):\n",
    "                break\n",
    "        # Decode the predicted IDs\n",
    "        pred_fr = de_tokenizer.decode(pred_ids)\n",
    "        print(f\"English: {en}\")\n",
    "        print(f\"Deutsch: {true_fr}\")\n",
    "        print(f\"Predicted: {pred_fr}\")\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
