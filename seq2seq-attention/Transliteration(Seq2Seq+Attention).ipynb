{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJGml5sGGHGM"
      },
      "source": [
        "## Custom Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDDuDBkmH8qj",
        "outputId": "38cb182b-78d7-4584-9d0f-34a3a974df7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: hello world\n",
            "Encoded: [[4, 5, 35, 32, 39, 39, 42], [4, 5, 50, 42, 45, 39, 31]]\n",
            "Decoded: hello, world, \n",
            "Original: [('hello', 'हेलो'), ('computer', 'कम्प्यूटर'), ('mobile', 'मोबाइल'), ('doctor', 'डॉक्टर'), ('school', 'स्कूल'), ('radio', 'रेडियो'), ('hello', 'bonjour'), ('computer', 'ordinateur'), ('mobile', 'mobile'), ('doctor', 'docteur'), ('school', 'école'), ('radio', 'radio'), ('hello', 'hallo'), ('computer', 'computer'), ('mobile', 'handy'), ('doctor', 'arzt'), ('school', 'schule'), ('radio', 'radio')]\n",
            "Source Encoded: [[4, 5, 35, 32, 39, 39, 42], [4, 5, 30, 42, 40, 43, 48, 47, 32, 45], [4, 5, 40, 42, 29, 36, 39, 32], [4, 5, 31, 42, 30, 47, 42, 45], [4, 5, 46, 30, 35, 42, 42, 39], [4, 5, 45, 28, 31, 36, 42], [4, 5, 35, 32, 39, 39, 42], [4, 5, 30, 42, 40, 43, 48, 47, 32, 45], [4, 5, 40, 42, 29, 36, 39, 32], [4, 5, 31, 42, 30, 47, 42, 45], [4, 5, 46, 30, 35, 42, 42, 39], [4, 5, 45, 28, 31, 36, 42], [4, 5, 35, 32, 39, 39, 42], [4, 5, 30, 42, 40, 43, 48, 47, 32, 45], [4, 5, 40, 42, 29, 36, 39, 32], [4, 5, 31, 42, 30, 47, 42, 45], [4, 5, 46, 30, 35, 42, 42, 39], [4, 5, 45, 28, 31, 36, 42]]\n",
            "Decoded: hello, computer, mobile, doctor, school, radio, hello, computer, mobile, doctor, school, radio, hello, computer, mobile, doctor, school, radio, \n",
            "Target Encoded: [[3, 5, 113, 69, 108, 71, 1], [3, 5, 117, 105, 121, 101, 121, 106, 68, 91, 124, 1], [3, 5, 105, 71, 103, 64, 75, 108, 1], [3, 5, 93, 56, 117, 121, 91, 124, 1], [3, 5, 112, 121, 117, 68, 108, 1], [3, 5, 124, 69, 93, 65, 106, 71, 1], [3, 5, 29, 42, 41, 37, 42, 48, 45, 1], [3, 5, 42, 45, 31, 36, 41, 28, 47, 32, 48, 45, 1], [3, 5, 40, 42, 29, 36, 39, 32, 1], [3, 5, 31, 42, 30, 47, 32, 48, 45, 1], [3, 5, 2, 30, 42, 39, 32, 1], [3, 5, 45, 28, 31, 36, 42, 1], [3, 5, 35, 28, 39, 39, 42, 1], [3, 5, 30, 42, 40, 43, 48, 47, 32, 45, 1], [3, 5, 35, 28, 41, 31, 52, 1], [3, 5, 28, 45, 53, 47, 1], [3, 5, 46, 30, 35, 48, 39, 32, 1], [3, 5, 45, 28, 31, 36, 42, 1]]\n",
            "Decoded: हेलो, कम्प्यूटर, मोबाइल, डॉक्टर, स्कूल, रेडियो, bonjour, ordinateur, mobile, docteur, cole, radio, hallo, computer, handy, arzt, schule, radio, \n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "import pickle\n",
        "import torch\n",
        "class CharVocab:\n",
        "  def __init__(self):\n",
        "      # English\n",
        "      chars = '0123456789'+ \\\n",
        "        '०१२३४५६७८९' + \\\n",
        "        'abcdefghijklmnopqrstuvwxyz' + \\\n",
        "        'ँंॉॆॊॏऺऻॎःािीुूेैोौअआइईउऊएऐओऔकखगघचछजझटठडढणतथदधनपफबभमयरलवशषसहज्ञक्षश्रज़रफ़ड़ढ़ख़क़ग़ळृृ़़ऑ' # + \\\n",
        "        # 'äöüß' + \\\n",
        "        # 'àâæçéèêëîïôœùûüÿ'\n",
        "\n",
        "      self.len = 0\n",
        "      # Codes\n",
        "      self.special_tokens = {'<pad>': 0, '<eos>': 1, '<unk>': 2, '<sos>': 3}\n",
        "\n",
        "      # Language Tags\n",
        "      self.lang_tags = {'<en>':4, '<hi>':5, '<de>':6, '<fr>':7 }\n",
        "\n",
        "      # Alphabets\n",
        "      self.alpha = chars\n",
        "\n",
        "      # Vocabulary\n",
        "      self.vocab = self.build()\n",
        "\n",
        "  def info(self):\n",
        "    return {\n",
        "        'special_tokens':self.special_tokens,\n",
        "        'lang_tags':self.lang_tags,\n",
        "        'alpha':self.alpha\n",
        "    }\n",
        "  def __len__(self):\n",
        "    return self.len\n",
        "\n",
        "  def build(self):\n",
        "    class Vocab:\n",
        "      def __init__(self, ctoi, itoc):\n",
        "        self.ctoi = ctoi\n",
        "        self.itoc = itoc\n",
        "\n",
        "    ctoi = {}\n",
        "    self.len = 0\n",
        "    for k in self.special_tokens:\n",
        "      ctoi[k] = self.special_tokens[k]\n",
        "      self.len += 1\n",
        "    for i, k in enumerate(self.lang_tags.keys(), len(ctoi)):\n",
        "      ctoi[k] = i\n",
        "      self.len += 1\n",
        "    for i, k in enumerate(self.alpha, len(ctoi)):\n",
        "      ctoi[k] = i\n",
        "      self.len += 1\n",
        "    itoc = {v:k for k,v in ctoi.items()}\n",
        "\n",
        "    return Vocab(ctoi, itoc)\n",
        "\n",
        "  def encode(self, inp, src_lang=None, tgt_lang=None):\n",
        "    if not src_lang and not tgt_lang:\n",
        "      raise Exception('Language not specified')\n",
        "    inp_tokens = []\n",
        "    if isinstance(inp, str):\n",
        "      inp = inp.strip().split()\n",
        "      prefix = [self.lang_tags[src_lang], self.lang_tags[tgt_lang]] # self.lang_tags[tgt_lang]\n",
        "      for word in inp:\n",
        "        tokens = []\n",
        "        tokens.extend(list(word))\n",
        "        tokens = [self.vocab.ctoi[char] if char in self.vocab.ctoi else self.vocab.ctoi['<unk>'] for char in tokens]\n",
        "        inp_tokens.append(prefix+tokens)\n",
        "    elif isinstance(inp, list) and isinstance(inp[0], tuple):\n",
        "      src_word, tgt_word = zip(*inp)\n",
        "      src_prefix = [self.lang_tags[src_lang], self.lang_tags[tgt_lang]] # self.lang_tags[tgt_lang]\n",
        "      src_tokens = []\n",
        "      for w in src_word:\n",
        "        tokens = []\n",
        "        tokens.extend(list(w))\n",
        "        tokens = [self.vocab.ctoi[char] if char in self.vocab.ctoi else self.vocab.ctoi['<unk>'] for char in tokens]\n",
        "        src_tokens.append(src_prefix+tokens)\n",
        "\n",
        "      tgt_tokens = []\n",
        "      tgt_prefix = [self.special_tokens['<sos>'], self.lang_tags[tgt_lang]] # self.lang_tags[tgt_lang]\n",
        "      for w in tgt_word:\n",
        "        tokens = []\n",
        "        tokens.extend(list(w))\n",
        "        tokens = [self.vocab.ctoi[char] if char in self.vocab.ctoi else self.vocab.ctoi['<unk>'] for char in tokens]\n",
        "        tokens.append(self.special_tokens['<eos>'])\n",
        "        tgt_tokens.append(tgt_prefix+tokens)\n",
        "      inp_tokens = (src_tokens, tgt_tokens)\n",
        "    return inp_tokens\n",
        "\n",
        "  def decode(self, ids):\n",
        "    if isinstance(ids, torch.Tensor):\n",
        "      ids = ids.tolist()\n",
        "      \n",
        "    if isinstance(ids, list):\n",
        "      decoded_word = []\n",
        "      for id in ids:\n",
        "        if id not in self.special_tokens.values() and id not in self.lang_tags.values():\n",
        "          if id in self.vocab.itoc.keys():\n",
        "            decoded_word.append(self.vocab.itoc[id])\n",
        "          # else:\n",
        "          #   decoded_word.append(self.vocab.itoc[2])\n",
        "    return ''.join(decoded_word)\n",
        "\n",
        "# encode : 'hello world' '<en>' '<hi>' -> [[4,5,...], [4,5...]]\n",
        "# encode : [(\"hello\", \"हेलो\")] '<en>' '<hi>' -> [[4,5,...], [3,5,...,1]]\n",
        "# decode : [3,4,...] -> 'word'\n",
        "\n",
        "# Test 1\n",
        "inp = \"hello world\"\n",
        "vocab = CharVocab()\n",
        "encoded = vocab.encode(inp, src_lang='<en>', tgt_lang='<hi>')\n",
        "print(f\"Original: {inp}\")\n",
        "print(f\"Encoded: {encoded}\")\n",
        "print(\"Decoded: \",end='')\n",
        "for word_ids in encoded:\n",
        "  print(vocab.decode(word_ids), end=', ')\n",
        "print()\n",
        "\n",
        "# Test 2\n",
        "pairs = [(\"hello\", \"हेलो\"), (\"computer\", \"कम्प्यूटर\"), (\"mobile\", \"मोबाइल\"), (\"doctor\", \"डॉक्टर\"), (\"school\", \"स्कूल\"), (\"radio\", \"रेडियो\"),\n",
        " (\"hello\", \"bonjour\"),(\"computer\", \"ordinateur\"),(\"mobile\", \"mobile\"),(\"doctor\", \"docteur\"),(\"school\", \"école\"),(\"radio\", \"radio\"),\n",
        "  (\"hello\", \"hallo\"),(\"computer\", \"computer\"),(\"mobile\", \"handy\"),(\"doctor\", \"arzt\"),(\"school\", \"schule\"),(\"radio\", \"radio\")]\n",
        "\n",
        "print(f\"Original: {pairs}\")\n",
        "src_encoded, tgt_encoded = vocab.encode(pairs, src_lang='<en>', tgt_lang='<hi>')\n",
        "print(f\"Source Encoded: {src_encoded}\")\n",
        "print(\"Decoded: \",end='')\n",
        "for i in src_encoded:\n",
        "  print(vocab.decode(i), end=', ')\n",
        "print()\n",
        "print(f\"Target Encoded: {tgt_encoded}\")\n",
        "print(\"Decoded: \",end='')\n",
        "for i in tgt_encoded:\n",
        "  print(vocab.decode(i), end=', ')\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'<pad>': 0, '<eos>': 1, '<unk>': 2, '<sos>': 3, '<en>': 4, '<hi>': 5, '<de>': 6, '<fr>': 7, '0': 8, '1': 9, '2': 10, '3': 11, '4': 12, '5': 13, '6': 14, '7': 15, '8': 16, '9': 17, '०': 18, '१': 19, '२': 20, '३': 21, '४': 22, '५': 23, '६': 24, '७': 25, '८': 26, '९': 27, 'a': 28, 'b': 29, 'c': 30, 'd': 31, 'e': 32, 'f': 33, 'g': 34, 'h': 35, 'i': 36, 'j': 37, 'k': 38, 'l': 39, 'm': 40, 'n': 41, 'o': 42, 'p': 43, 'q': 44, 'r': 45, 's': 46, 't': 47, 'u': 48, 'v': 49, 'w': 50, 'x': 51, 'y': 52, 'z': 53, 'ँ': 54, 'ं': 55, 'ॉ': 56, 'ॆ': 57, 'ॊ': 58, 'ॏ': 59, 'ऺ': 60, 'ऻ': 61, 'ॎ': 62, 'ः': 63, 'ा': 64, 'ि': 65, 'ी': 66, 'ु': 67, 'ू': 68, 'े': 69, 'ै': 70, 'ो': 71, 'ौ': 72, 'अ': 73, 'आ': 74, 'इ': 75, 'ई': 76, 'उ': 77, 'ऊ': 78, 'ए': 79, 'ऐ': 80, 'ओ': 81, 'औ': 82, 'क': 117, 'ख': 84, 'ग': 85, 'घ': 86, 'च': 87, 'छ': 88, 'ज': 114, 'झ': 90, 'ट': 91, 'ठ': 92, 'ड': 93, 'ढ': 94, 'ण': 95, 'त': 96, 'थ': 97, 'द': 98, 'ध': 99, 'न': 100, 'प': 101, 'फ': 102, 'ब': 103, 'भ': 104, 'म': 105, 'य': 106, 'र': 124, 'ल': 108, 'व': 109, 'श': 120, 'ष': 119, 'स': 112, 'ह': 113, '्': 121, 'ञ': 116, 'ज़': 123, 'फ़': 125, 'ड़': 126, 'ढ़': 127, 'ख़': 128, 'क़': 129, 'ग़': 130, 'ळ': 131, 'ृ': 133, '़': 135, 'ऑ': 136}\n",
            "{0: '<pad>', 1: '<eos>', 2: '<unk>', 3: '<sos>', 4: '<en>', 5: '<hi>', 6: '<de>', 7: '<fr>', 8: '0', 9: '1', 10: '2', 11: '3', 12: '4', 13: '5', 14: '6', 15: '7', 16: '8', 17: '9', 18: '०', 19: '१', 20: '२', 21: '३', 22: '४', 23: '५', 24: '६', 25: '७', 26: '८', 27: '९', 28: 'a', 29: 'b', 30: 'c', 31: 'd', 32: 'e', 33: 'f', 34: 'g', 35: 'h', 36: 'i', 37: 'j', 38: 'k', 39: 'l', 40: 'm', 41: 'n', 42: 'o', 43: 'p', 44: 'q', 45: 'r', 46: 's', 47: 't', 48: 'u', 49: 'v', 50: 'w', 51: 'x', 52: 'y', 53: 'z', 54: 'ँ', 55: 'ं', 56: 'ॉ', 57: 'ॆ', 58: 'ॊ', 59: 'ॏ', 60: 'ऺ', 61: 'ऻ', 62: 'ॎ', 63: 'ः', 64: 'ा', 65: 'ि', 66: 'ी', 67: 'ु', 68: 'ू', 69: 'े', 70: 'ै', 71: 'ो', 72: 'ौ', 73: 'अ', 74: 'आ', 75: 'इ', 76: 'ई', 77: 'उ', 78: 'ऊ', 79: 'ए', 80: 'ऐ', 81: 'ओ', 82: 'औ', 117: 'क', 84: 'ख', 85: 'ग', 86: 'घ', 87: 'च', 88: 'छ', 114: 'ज', 90: 'झ', 91: 'ट', 92: 'ठ', 93: 'ड', 94: 'ढ', 95: 'ण', 96: 'त', 97: 'थ', 98: 'द', 99: 'ध', 100: 'न', 101: 'प', 102: 'फ', 103: 'ब', 104: 'भ', 105: 'म', 106: 'य', 124: 'र', 108: 'ल', 109: 'व', 120: 'श', 119: 'ष', 112: 'स', 113: 'ह', 121: '्', 116: 'ञ', 123: 'ज़', 125: 'फ़', 126: 'ड़', 127: 'ढ़', 128: 'ख़', 129: 'क़', 130: 'ग़', 131: 'ळ', 133: 'ृ', 135: '़', 136: 'ऑ'}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "137"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dummy = CharVocab()\n",
        "print(dummy.vocab.ctoi)\n",
        "print(dummy.vocab.itoc)\n",
        "len(dummy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hN-gaTTNI6g",
        "outputId": "1c15ac73-feda-455b-a97f-0051ddeab495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "src: tensor([[ 4,  7, 40, 42, 29, 36, 39, 32],\n",
            "        [ 4,  5, 45, 28, 31, 36, 42,  0]])\n",
            "tgt: tensor([[  3,   7,  40,  42,  29,  36,  39,  32,   1],\n",
            "        [  3,   5, 124,  69,  93,  65, 106,  71,   1]])\n",
            "src_len: tensor([8, 7])\n",
            "torch.Size([2, 8]) torch.Size([2, 9]) tensor([8, 7])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class TransliterationDataset:\n",
        "  def __init__(self, pairs, tokenizer):\n",
        "    self.pairs = pairs\n",
        "    self.tokenizer = tokenizer\n",
        "    self.padding_value = tokenizer.vocab.ctoi['<pad>']\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.pairs)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    pair, lang_pair = self.pairs[idx][:2], self.pairs[idx][2]\n",
        "    src_ids, tgt_ids = self.tokenizer.encode([pair], src_lang=lang_pair[0], tgt_lang=lang_pair[1])\n",
        "    return torch.tensor(src_ids[0], dtype=torch.long), torch.tensor(tgt_ids[0], dtype=torch.long)\n",
        "\n",
        "  def collate_fn(self, batch):\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "    src_padded = torch.nn.utils.rnn.pad_sequence(src_batch, batch_first=True, padding_value=self.padding_value)\n",
        "    tgt_padded = torch.nn.utils.rnn.pad_sequence(tgt_batch, batch_first=True, padding_value=self.padding_value)\n",
        "    src_lengths = (src_padded != self.padding_value).sum(dim=1)\n",
        "    return src_padded, tgt_padded, src_lengths\n",
        "\n",
        "  def get_dataloader(self, batch_size, shuffle=True):\n",
        "    return DataLoader(self, batch_size=batch_size, shuffle=shuffle, collate_fn=self.collate_fn)\n",
        "\n",
        "# Test\n",
        "pairs = [\n",
        "    (\"hello\", \"हेलो\", (\"<en>\", \"<hi>\")), (\"computer\", \"कम्प्यूटर\", (\"<en>\", \"<hi>\")),\n",
        "    (\"mobile\", \"मोबाइल\", (\"<en>\", \"<hi>\")), (\"doctor\", \"डॉक्टर\", (\"<en>\", \"<hi>\")),\n",
        "    (\"school\", \"स्कूल\", (\"<en>\", \"<hi>\")), (\"radio\", \"रेडियो\", (\"<en>\", \"<hi>\")),\n",
        "\n",
        "    (\"hello\", \"bonjour\", (\"<en>\", \"<fr>\")), (\"computer\", \"ordinateur\", (\"<en>\", \"<fr>\")),\n",
        "    (\"mobile\", \"mobile\", (\"<en>\", \"<fr>\")), (\"doctor\", \"docteur\", (\"<en>\", \"<fr>\")),\n",
        "    (\"school\", \"école\", (\"<en>\", \"<fr>\")), (\"radio\", \"radio\", (\"<en>\", \"<fr>\")),\n",
        "\n",
        "    (\"hello\", \"hallo\", (\"<en>\", \"<de>\")), (\"computer\", \"computer\", (\"<en>\", \"<de>\")),\n",
        "    (\"mobile\", \"handy\", (\"<en>\", \"<de>\")), (\"doctor\", \"arzt\", (\"<en>\", \"<de>\")),\n",
        "    (\"school\", \"schule\", (\"<en>\", \"<de>\")), (\"radio\", \"radio\", (\"<en>\", \"<de>\"))\n",
        "]\n",
        "\n",
        "dataset = TransliterationDataset(pairs, tokenizer=vocab)\n",
        "dataloader = dataset.get_dataloader(batch_size=2)\n",
        "\n",
        "for src, tgt, src_len in dataloader:\n",
        "  print(f\"src: {src}\")\n",
        "  print(f\"tgt: {tgt}\")\n",
        "  print(f\"src_len: {src_len}\")\n",
        "  print(src.shape, tgt.shape, src_len)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIy0WUSmQtxx"
      },
      "source": [
        "## Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "e3wj2GdRQyMp"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "CnGMURjLNfcl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda\n",
            "Input Shape: torch.Size([1, 8]), Input Len: torch.Size([1]), \n",
            "Output Shape: torch.Size([8, 1, 512]), Hidden State Shape: torch.Size([4, 1, 512]), Cell State Shape: torch.Size([4, 1, 512])\n"
          ]
        }
      ],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self,\n",
        "      input_size, embedding_size, hidden_size,\n",
        "      num_layers=1,\n",
        "      dropout=0.01,\n",
        "      bidirectional=False,\n",
        "      arch = \"gru\",\n",
        "      batch_first=True\n",
        "    ):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.embedding_size = embedding_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.dropout_rate = dropout\n",
        "    self.directions = 2 if bidirectional else 1\n",
        "    self.arch = arch\n",
        "    self.batch_first = batch_first\n",
        "\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "    if self.arch == \"lstm\":\n",
        "      RNN = nn.LSTM\n",
        "    elif  self.arch == \"gru\":\n",
        "      RNN = nn.GRU\n",
        "    else:\n",
        "      raise Exception(\"Invalid Architecture\")\n",
        "    self.rnn = RNN(\n",
        "        input_size=embedding_size,\n",
        "        hidden_size=hidden_size,\n",
        "        num_layers=num_layers,\n",
        "        dropout=dropout,\n",
        "        bidirectional=bidirectional,\n",
        "        batch_first=batch_first\n",
        "    )\n",
        "    self.fc = nn.Linear(self.hidden_size*self.directions, hidden_size)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, src_padded, src_lengths):\n",
        "    embedded = self.dropout(self.embedding(src_padded))\n",
        "    embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_lengths, batch_first=True, enforce_sorted=False)\n",
        "    # hidden: (h_n, c_n) if LSTM else (n_layer**num_directions, batch_size, hidden_dim)\n",
        "    outputs, hidden = self.rnn(embedded)\n",
        "    # output: (batch_size, max_length, hidden_dim*directions)\n",
        "    outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
        "    # output: (batch_size, max_length, hidden_dim)\n",
        "    outputs = self.fc(outputs)\n",
        "    outputs = outputs.permute(1, 0, 2)  # (max_length, batch_size, hidden_dim)\n",
        "    return outputs, hidden\n",
        "  \n",
        "\n",
        "# Test\n",
        "enc_vocab = CharVocab()\n",
        "enc_pairs = [\n",
        "  (\"hello\", \"हेलो\", (\"<en>\", \"<hi>\")), (\"computer\", \"कम्प्यूटर\", (\"<en>\", \"<hi>\")),\n",
        "    (\"mobile\", \"मोबाइल\", (\"<en>\", \"<hi>\")), (\"doctor\", \"डॉक्टर\", (\"<en>\", \"<hi>\")),\n",
        "    (\"school\", \"स्कूल\", (\"<en>\", \"<hi>\")), (\"radio\", \"रेडियो\", (\"<en>\", \"<hi>\"))\n",
        "]\n",
        "enc_dataset = TransliterationDataset(enc_pairs, vocab)\n",
        "enc = Encoder(\n",
        "      input_size = len(enc_vocab), embedding_size = 256, hidden_size = 512,\n",
        "      num_layers=2,\n",
        "      dropout=0.03,\n",
        "      bidirectional=True,\n",
        "      arch = \"lstm\",\n",
        "      batch_first=True\n",
        ")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using {device}\")\n",
        "enc.to(device)\n",
        "\n",
        "for src_padded, tgt_padded, src_len in enc_dataset.get_dataloader(batch_size=1):\n",
        "  src_padded = src_padded.to(device)\n",
        "  print(f\"Input Shape: {src_padded.shape}, Input Len: {src_len.shape}, \")\n",
        "  outputs, hidden = enc(src_padded, src_len)\n",
        "  print(f\"Output Shape: {outputs.shape}, Hidden State Shape: {hidden[0].shape}, Cell State Shape: {hidden[1].shape}\")\n",
        "  break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "Zn1lN17XO9vJ"
      },
      "outputs": [],
      "source": [
        "class LuongAttention(nn.Module):\n",
        "    def __init__(self, method, hidden_size):\n",
        "        super(LuongAttention, self).__init__()\n",
        "        self.method = method\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        if self.method == 'general':\n",
        "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
        "        elif self.method == 'concat':\n",
        "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
        "            self.v = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
        "\n",
        "    def dot_score(self, hidden, encoder_output):\n",
        "        return torch.sum(hidden * encoder_output, dim=2)\n",
        "\n",
        "    def general_score(self, hidden, encoder_output):\n",
        "        energy = self.attn(encoder_output)\n",
        "        return torch.sum(hidden * energy, dim=2)\n",
        "\n",
        "    def concat_score(self, hidden, encoder_output):\n",
        "        hidden = hidden.repeat(encoder_output.size(0), 1, 1)\n",
        "        energy = self.attn(torch.cat([hidden, encoder_output], 2)).tanh()\n",
        "        return torch.sum(self.v * energy, dim=2)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        if self.method == 'general':\n",
        "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
        "        elif self.method == 'concat':\n",
        "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
        "        elif self.method == 'dot':\n",
        "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
        "\n",
        "        attn_energies = attn_energies.t()\n",
        "        #  attn_weights: shape: (batch_size, 1, seq_len)\n",
        "        attn_weights = nn.functional.softmax(attn_energies, dim=1).unsqueeze(1)\n",
        "        # context: shape: (batch_size, 1, hidden_size)\n",
        "        context = torch.bmm(attn_weights, encoder_outputs.transpose(0, 1))\n",
        "        return context, attn_weights\n",
        "    \n",
        "# Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "9exBrrKAQ9bC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda\n",
            "Input Shape: torch.Size([4, 10]), Input Len: torch.Size([4]), \n",
            "Output Shape: torch.Size([10, 4, 512]), Hidden State Shape: torch.Size([4, 4, 512]), Cell State Shape: torch.Size([4, 4, 512])\n",
            "Prediction Shape: torch.Size([4, 1, 137]), Hidden State Shape: torch.Size([4, 4, 512]), Cell State Shape: torch.Size([4, 4, 512])\n"
          ]
        }
      ],
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self,\n",
        "      vocab_size, embedding_size, hidden_size,\n",
        "      num_layers=1,\n",
        "      dropout=0.01,\n",
        "      bidirectional=False,\n",
        "      batch_first=True,\n",
        "      arch = \"lstm\",\n",
        "      attn = \"dot\",\n",
        "    ):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.input_size = vocab_size\n",
        "    self.embedding_size = embedding_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = vocab_size\n",
        "    self.num_layers = num_layers\n",
        "    self.dropout_rate = dropout\n",
        "    self.directions = 2 if bidirectional else 1\n",
        "    self.batch_first = batch_first\n",
        "    self.arch = arch\n",
        "    self.attn_method = attn\n",
        "\n",
        "    self.embedding = nn.Embedding(self.input_size, embedding_size)\n",
        "    self.attention = LuongAttention(attn, hidden_size)\n",
        "    if self.arch == \"lstm\":\n",
        "      RNN = nn.LSTM\n",
        "    elif  self.arch == \"gru\":\n",
        "      RNN = nn.GRU\n",
        "    else:\n",
        "      raise Exception(\"Invalid Architecture\")\n",
        "    self.rnn = RNN(\n",
        "        input_size=embedding_size+hidden_size,\n",
        "        hidden_size=hidden_size,\n",
        "        num_layers=num_layers,\n",
        "        dropout=dropout,\n",
        "        bidirectional=bidirectional,\n",
        "        batch_first=batch_first\n",
        "    )\n",
        "    self.hid_attn = nn.Linear(self.num_layers * self.directions, 1)\n",
        "    self.fc = nn.Sequential(\n",
        "            nn.Linear(self.hidden_size*self.directions, self.embedding_size), nn.LeakyReLU(),\n",
        "            nn.Linear(self.embedding_size, self.output_size),\n",
        "    )\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, tgt_padded, hidden, enc_out):\n",
        "\n",
        "    if hidden is None:\n",
        "       h_0 = torch.zeros(\n",
        "          self.num_layers*self.directions,\n",
        "          tgt_padded.size(0),\n",
        "          self.hidden_size,\n",
        "          device=tgt_padded.device\n",
        "       )\n",
        "       if self.arch ==\"lstm\":\n",
        "          c_0 = torch.zeros_like(h_0)\n",
        "          hidden = (h_0, c_0)\n",
        "       else:\n",
        "          hidden = h_0\n",
        "\n",
        "    if self.arch == \"lstm\" and isinstance(hidden,tuple):\n",
        "      hidden_ = hidden[0]\n",
        "    else:\n",
        "      hidden_ = hidden\n",
        "\n",
        "    # [L*D, B, H]\n",
        "    hidden_ = hidden_.permute(1, 2, 0)           # [B, H, L*D]\n",
        "    attn_inp = self.hid_attn(hidden_)            # [B, H, 1]\n",
        "    attn_inp = attn_inp.permute(2, 0, 1)         # [1, B, H]\n",
        "\n",
        "    # print(f\"Eo: {enc_out.shape}, Attin: {attn_inp.shape}\")\n",
        "    context, attn_weights = self.attention(attn_inp, enc_out)\n",
        "    embedded = self.dropout(self.embedding(tgt_padded))\n",
        "    context = context.repeat(1, embedded.size(1), 1)\n",
        "    rnn_input = torch.cat([embedded, context], dim=2)\n",
        "    # hidden: (h_n, c_n) if LSTM else (n_layer**num_directions, batch_size, hidden_dim)\n",
        "    outputs, hidden = self.rnn(rnn_input, hidden)\n",
        "    output = self.fc(outputs)\n",
        "    return output, hidden\n",
        "  \n",
        "\n",
        "# Test\n",
        "test_vocab = CharVocab()\n",
        "test_pairs = [\n",
        "  (\"hello\", \"हेलो\", (\"<en>\", \"<hi>\")), (\"computer\", \"कम्प्यूटर\", (\"<en>\", \"<hi>\")),\n",
        "    (\"mobile\", \"मोबाइल\", (\"<en>\", \"<hi>\")), (\"doctor\", \"डॉक्टर\", (\"<en>\", \"<hi>\")),\n",
        "    (\"school\", \"स्कूल\", (\"<en>\", \"<hi>\")), (\"radio\", \"रेडियो\", (\"<en>\", \"<hi>\"))\n",
        "]\n",
        "test_dataset = TransliterationDataset(test_pairs, test_vocab)\n",
        "enc = Encoder(\n",
        "      input_size = len(test_vocab), embedding_size = 256, hidden_size = 512,\n",
        "      num_layers=2,\n",
        "      dropout=0.03,\n",
        "      bidirectional=True,\n",
        "      arch = \"lstm\",\n",
        "      batch_first=True\n",
        ")\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device}\")\n",
        "enc.to(device)\n",
        "\n",
        "dec = Decoder(\n",
        "  vocab_size = len(test_vocab), embedding_size=256, hidden_size=512,\n",
        "      num_layers=2,\n",
        "      dropout=0.01,\n",
        "      bidirectional=True,\n",
        "      batch_first=True,\n",
        "      arch = \"lstm\",\n",
        "      attn = \"dot\",\n",
        ")\n",
        "dec.to(device)\n",
        "for src_padded, tgt_padded, src_len in test_dataset.get_dataloader(batch_size=4):\n",
        "  src_padded = src_padded.to(device)\n",
        "  print(f\"Input Shape: {src_padded.shape}, Input Len: {src_len.shape}, \")\n",
        "  outputs, hidden = enc(src_padded, src_len)\n",
        "  print(f\"Output Shape: {outputs.shape}, Hidden State Shape: {hidden[0].shape}, Cell State Shape: {hidden[1].shape}\")\n",
        "  dec_in = tgt_padded[:, :1].to(device)\n",
        "  prediction, hidden = dec(dec_in, hidden, outputs)\n",
        "  print(f\"Prediction Shape: {prediction.shape}, Hidden State Shape: {hidden[0].shape}, Cell State Shape: {hidden[1].shape}\")\n",
        "  break\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda\n",
            "Input Shape: torch.Size([6, 10]), Input Len: torch.Size([6])\n",
            "Output Shape: torch.Size([6, 11, 137])\n",
            "Done\n",
            "Test Input: Hy this is test case.\n",
            "Test Output: ंःःःःःzzzछ ः8औछछछ8छछछ ः8छछछछछछछछ ः8औछछछछछछछ छछछछz8छछछछ\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "class TransliterationModel(nn.Module):\n",
        "    def __init__(self, enc_class, dec_class, vocab_sz, embed_sz=256, hidden_sz=512, num_layers=2, bidir=True, dropout=0.03, arch='lstm', attn='dot'):\n",
        "        super(TransliterationModel, self).__init__()\n",
        "        self.batch_first = True\n",
        "        self.dirs = 2 if bidir else 1\n",
        "        self.attn = attn\n",
        "        self.arch = arch\n",
        "        self.dropout = dropout\n",
        "        self.enc = enc_class(\n",
        "            input_size = vocab_sz, embedding_size = embed_sz, hidden_size = hidden_sz,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout,\n",
        "            bidirectional=bidir,\n",
        "            arch = arch,\n",
        "            batch_first=True\n",
        "            )\n",
        "        self.dec = dec_class(\n",
        "            vocab_size = vocab_sz, embedding_size=embed_sz, hidden_size=hidden_sz,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout,\n",
        "            bidirectional=bidir,\n",
        "            batch_first=True,\n",
        "            arch = arch,\n",
        "            attn = attn,\n",
        "        )\n",
        "    \n",
        "    def forward(self, src, src_len, tgt, tfr=0.7):\n",
        "        tgt_len = tgt.shape[1]\n",
        "        outputs = []\n",
        "        _enc_outs, _enc_hidd = self.enc(src, src_len)\n",
        "        _dec_hidd = _enc_hidd\n",
        "        _dec_in = tgt[:,:1]\n",
        "\n",
        "        for t in range(tgt_len-1):\n",
        "            pred, _dec_hidd = self.dec(_dec_in, _dec_hidd, _enc_outs)\n",
        "            pred = pred[:, -1:, :] # [batch, 1, vocab]\n",
        "            outputs.append(pred)\n",
        "\n",
        "            use_teacher = torch.rand(1).item() < tfr\n",
        "            if use_teacher:\n",
        "                # use the target token as the next input\n",
        "                _dec_in = tgt[:, t+1:t+2]\n",
        "            else:\n",
        "                # use the predicted token as the next input\n",
        "                _dec_in = pred.argmax(dim=2)\n",
        "\n",
        "        outputs = torch.cat(outputs, dim=1)\n",
        "        return outputs\n",
        "    \n",
        "    def generate(self, input_text: str, vocab: CharVocab, src_lang, tgt_lang, device, maxlen=25)-> str:\n",
        "        with torch.no_grad():\n",
        "            outs = []\n",
        "            pad_id = vocab.special_tokens['<pad>']\n",
        "            input_text = input_text.strip().lower()\n",
        "            input_text = re.sub(r'\\s+', ' ', input_text)\n",
        "            input_tokens = input_text.split()\n",
        "            for token in input_tokens:\n",
        "                encoded = vocab.encode(token, src_lang=src_lang, tgt_lang=tgt_lang)\n",
        "                encoded = [torch.tensor(encoded[0], dtype=torch.long)]\n",
        "                encoded_padded = torch.nn.utils.rnn.pad_sequence(encoded, batch_first=True, padding_value=pad_id).to(device)\n",
        "                src_lengths = (encoded_padded != pad_id).sum(dim=1).cpu()\n",
        "                # encoded_padded = torch.Tensor(encoded_padded, dtype=torch.long).to(device)\n",
        "                _enc_outs, _enc_hidd = self.enc(encoded_padded, src_lengths)\n",
        "                _dec_hidd = _enc_hidd\n",
        "                \n",
        "                _dec_in = torch.full((1, 1), vocab.special_tokens['<sos>'], dtype=torch.long, device=device)\n",
        "                pred_ids = [_dec_in]\n",
        "                for m in range(maxlen):\n",
        "                    pred, _dec_hidd = self.dec(_dec_in, _dec_hidd, _enc_outs)\n",
        "                    pred = pred[:, -1:, :].argmax(dim=-1)  # [batch, seq_len, vocab] -> [batch, 1, vocab] - > [batch]\n",
        "                    next_token = pred[0][0].item()\n",
        "                    pred_ids.append(next_token)\n",
        "                    _dec_in = torch.full((1, 1), next_token , dtype=torch.long, device=device)\n",
        "                    \n",
        "                    if next_token == vocab.special_tokens['<eos>']:\n",
        "                        break\n",
        "                # pred_ids = torch.cat(pred_ids, dim=1)\n",
        "                # pred_ids = pred_ids.tolist()\n",
        "                outs.append(vocab.decode(pred_ids))\n",
        "\n",
        "            return ' '.join(outs)\n",
        "                     \n",
        "    \n",
        "# Test\n",
        "test_vocab = CharVocab()\n",
        "test_pairs = [\n",
        "  (\"hello\", \"हेलो\", (\"<en>\", \"<hi>\")), (\"computer\", \"कम्प्यूटर\", (\"<en>\", \"<hi>\")),\n",
        "    (\"mobile\", \"मोबाइल\", (\"<en>\", \"<hi>\")), (\"doctor\", \"डॉक्टर\", (\"<en>\", \"<hi>\")),\n",
        "    (\"school\", \"स्कूल\", (\"<en>\", \"<hi>\")), (\"radio\", \"रेडियो\", (\"<en>\", \"<hi>\"))\n",
        "]\n",
        "test_dataset = TransliterationDataset(test_pairs, test_vocab)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device}\")\n",
        "\n",
        "test_model = TransliterationModel(Encoder, Decoder, vocab_sz=len(test_vocab))\n",
        "test_model.to(device)\n",
        "\n",
        "test_model.eval()\n",
        "# Test 1\n",
        "for src_padded, tgt_padded, src_len in test_dataset.get_dataloader(batch_size=64):\n",
        "  src_padded, tgt_padded = src_padded.to(device), tgt_padded.to(device)\n",
        "  print(f\"Input Shape: {src_padded.shape}, Input Len: {src_len.shape}\")\n",
        "  outputs = test_model(src_padded, src_len, tgt_padded)\n",
        "  print(f\"Output Shape: {outputs.shape}\")\n",
        "  break\n",
        "\n",
        "print('Done')\n",
        "\n",
        "# Test 2\n",
        "test_input = \"Hy this is test case.\"\n",
        "test_output = test_model.generate(test_input, vocab=test_vocab, src_lang='<en>', tgt_lang='<hi>', device=device, maxlen=10)\n",
        "print(f\"Test Input: {test_input}\") \n",
        "print(f\"Test Output: {test_output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFkW1fI_gPqJ"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yR6CfoHgIPZ"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "RGX54_0vacgJ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "with open(\"hin_train.json\", \"r\") as f:\n",
        "  hin_train = [json.loads(line) for line in f]\n",
        "with open(\"hin_valid.json\", \"r\") as f:\n",
        "  hin_valid = [json.loads(line) for line in f]\n",
        "\n",
        "# Convert train split to pandas DataFrame\n",
        "train_ = pd.DataFrame(hin_train)\n",
        "valid_ = pd.DataFrame(hin_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHeE501Khd3c"
      },
      "outputs": [],
      "source": [
        "en_hin_train = [(row[\"english word\"], row[\"native word\"], (\"<en>\", \"<hi>\")) for _, row in train_.iterrows()]\n",
        "en_hin_valid = [(row[\"english word\"], row[\"native word\"], (\"<en>\", \"<hi>\")) for _, row in valid_.iterrows()]\n",
        "# hin_en_train = [(row[\"native word\"],row[\"english word\"], (\"<hi>\", \"<en>\")) for _, row in train_.iterrows()]\n",
        "# hin_en_valid = [(row[\"native word\"],row[\"english word\"], (\"<hi>\", \"<en>\")) for _, row in train_.iterrows()]\n",
        "\n",
        "# train_pairs = en_hin_train + hin_en_train\n",
        "# valid_pairs = en_hin_valid + hin_en_valid\n",
        "\n",
        "# comment bellow line and uncomment other lines for bi directional\n",
        "train_pairs = en_hin_train\n",
        "valid_pairs = en_hin_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pickle\n",
        "\n",
        "# with open(\"train_pairs.pkl\", 'wb') as f:\n",
        "#     pickle.dump(train_pairs, f)\n",
        "\n",
        "# with open(\"valid_pairs.pkl\", 'wb') as f:\n",
        "#     pickle.dump(valid_pairs, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pickle\n",
        "\n",
        "# with open(\"train_pairs.pkl\", 'rb') as f:\n",
        "#     train_pairs = pickle.load(f)\n",
        "\n",
        "# with open(\"valid_pairs.pkl\", 'rb') as f:\n",
        "#     valid_pairs = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lf9HAOf3T0Ep",
        "outputId": "3cbaecd8-7804-45ad-a809-feab1763d7cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda\n"
          ]
        }
      ],
      "source": [
        "vocab = CharVocab()\n",
        "train_df = TransliterationDataset(train_pairs[:32000], vocab)\n",
        "train_loader = train_df.get_dataloader(batch_size=128)\n",
        "\n",
        "val_df = TransliterationDataset(valid_pairs, vocab)\n",
        "eval_loader = val_df.get_dataloader(batch_size=128)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device}\")\n",
        "\n",
        "main_model = TransliterationModel(Encoder, Decoder, vocab_sz=len(vocab))\n",
        "main_model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=vocab.special_tokens['<pad>'])\n",
        "optimizer = torch.optim.AdamW(main_model.parameters(), lr=1e-3, weight_decay=5e-3)\n",
        "\n",
        "epochs = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tqdm\n",
        "def train(model, trainloader, optimizer, criterion, device, epochs=1, evaloader=None):\n",
        "    train_loss = 0\n",
        "    for e in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        model.train()\n",
        "        for src_tagged, tgt_tagged, src_len in tqdm.tqdm(trainloader, desc=\"Training\"):\n",
        "            src_padded = src_tagged.to(device)\n",
        "            tgt_padded = tgt_tagged.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(src_padded, src_len, tgt_padded)\n",
        "            # compute the loss: compare 3D logits to 2D targets\n",
        "            loss = criterion(output.view(-1, output.shape[-1]), tgt_padded[:, 1:].reshape(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        if e < epochs-1:\n",
        "          print(f\"Epoch {e+1}/{epochs} completed with epoch loss of {epoch_loss/len(trainloader):.4f}\")\n",
        "        train_loss += epoch_loss/len(trainloader)\n",
        "        # if (e+1)%5 != 0 or not evaloader:\n",
        "        #     continue\n",
        "        eval_loss = 0\n",
        "        model.eval()\n",
        "        for src_tagged, tgt_tagged, src_len in tqdm.tqdm(evaloader, desc=\"Validation\"):\n",
        "            src_padded = src_tagged.to(device)\n",
        "            tgt_padded = tgt_tagged.to(device)\n",
        "            with torch.no_grad():\n",
        "              output = model(src_padded, src_len, tgt_padded)\n",
        "              # compute the loss: compare 3D logits to 2D targets\n",
        "              loss = criterion(output.view(-1, output.shape[-1]), tgt_padded[:, 1:].reshape(-1))\n",
        "              eval_loss += loss.item()\n",
        "        print(f\"Evaluation completed with epoch loss of {eval_loss/len(evaloader):.4f}\")\n",
        "        torch.save(main_model, f\"en_hi_tlite_lstm2_{e+1}.pth\")\n",
        "    print(f\"\\nTraining completed with training loss of {train_loss/epochs:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 1000/1000 [02:08<00:00,  7.76it/s]\n",
            "Validation: 100%|██████████| 199/199 [00:04<00:00, 40.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation completed with epoch loss of 0.7270\n",
            "\n",
            "Training completed with training loss of 1.2725\n"
          ]
        }
      ],
      "source": [
        "train(\n",
        "    model=main_model, \n",
        "    trainloader=train_loader, \n",
        "    optimizer=optimizer, \n",
        "    criterion=criterion, \n",
        "    device=device, \n",
        "    epochs=epochs, \n",
        "    evaloader=eval_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(main_model.state_dict(), 'model_weights.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OlwmgJ7gZD5"
      },
      "source": [
        "## Predicting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "39ZbVurkV0tK"
      },
      "outputs": [],
      "source": [
        "def predict(model, tokenizer, input_seq, src_lang='<en>', tgt_lang='<hi>', device=\"cpu\"):\n",
        "    output = model.generate(input_seq, tokenizer, src_lang=src_lang, tgt_lang=tgt_lang, device=device)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "हेलो वोर्लो\n"
          ]
        }
      ],
      "source": [
        "inp_pred = \"Hello World!\"\n",
        "pred_vocab = CharVocab()\n",
        "model = TransliterationModel(Encoder, Decoder, vocab_sz=len(vocab))\n",
        "model.load_state_dict(torch.load(\"en_hi_tlite_lstm2_1.pth\"))\n",
        "model.to(device)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(predict(model, pred_vocab, inp_pred, device=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VitejEVCwgPb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FipCn41T00Cq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "CJGml5sGGHGM",
        "IIy0WUSmQtxx",
        "lFkW1fI_gPqJ",
        "2OlwmgJ7gZD5"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
